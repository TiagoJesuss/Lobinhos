# AI Claim Assistant

An AI-powered virtual insurance agent that can retrieve claim information and speak with users in real time using ElevenLabs voice synthesis, n8n workflows, and an Airtable database.

## Overview

This project demonstrates how to build an interactive voice assistant capable of handling customer claim inquiries. The assistant receives a request, retrieves information from Airtable via n8n, and responds with natural-sounding speech generated by ElevenLabs.

## System Architecture

```
ElevenLabs Agent (voice input)
        ↓ Webhook call
     n8n Workflow
        ↓
  Airtable (Users + Claims)
        ↓
  ElevenLabs (TTS / AI Agent)
        ↓
Python + Local Web Server
        ↓
HTML Frontend
```

## Technical Workflow

1. **Airtable Database**  
   - Two tables:  
     - `Users` – stores customer data (`name`, `email`, `ssn_hash`, etc.)  
     - `Claims` – stores claim information (`claim_id`, `status`, `linked_user`, etc.)  
   - Sensitive data like SSN is hashed (SHA-256) before being stored.

2. **n8n Workflow**  
   - Acts as the integration and logic layer.  
   - Contains the following nodes:
     - **Webhook Node** – receives the incoming HTTP request from the ElevenLabs agent.  
     - **Crypto Node** – hashes the SSN for secure user lookup.  
     - **Airtable Nodes** – find the corresponding user and claim.  
     - **Logic/Function Nodes** – format the response message.  
     - **ElevenLabs Node (HTTP Request)** – sends the response text to the ElevenLabs Text-to-Speech API.  
     - **Webhook Response Node** – returns both text and generated audio back to the frontend.

3. **Python Local Server**  
   - A small Flask (or FastAPI) server runs locally to simulate the virtual call environment.  
   - It serves an HTML page and handles `/speak` requests from the web interface.  
   - When triggered, the Python script calls the n8n webhook, waits for the response (text + audio), and passes it to the ElevenLabs agent API.

4. **HTML Frontend**  
   - A simple webpage rendered locally through Flask.  
   - Has a button that when pressed starts the call with the ElevenLabs virtual agent.  

## Data Flow

1. User (or AI agent) sends a POST request:
   ```json
   { "ssn": "123456789", "claim_id": "1" }
   ```

2. The n8n webhook receives the request, processes the SSN hash, queries Airtable, and generates a text response.

3. The text is sent to ElevenLabs for TTS synthesis.

4. The response returned to the frontend contains:
   ```json
   {
     "text": "Your claim 1 has been approved and will be processed soon.",
     "audio_url": "https://.../tts_output.mp3"
   }
   ```

5. The Python local server sends this to the Beyond Presence avatar, which animates and speaks the reply.

## Key Technologies

| Component | Purpose |
|------------|----------|
| Airtable | Customer and claim data storage |
| n8n | Workflow automation and data orchestration |
| ElevenLabs API | Text-to-Speech generation |
| Python (Flask) | Local server to handle simulation requests |
| Beyond Presence SDK | 3D virtual avatar for the voice assistant UI |
| PyWebView (optional) | Runs the HTML frontend inside a native desktop window |

## Security Notes

- SSNs are never stored in plaintext.  
- Communication with Airtable and ElevenLabs is done via HTTPS and API keys.  
- The local simulation can be moved to a secured cloud instance if deployed publicly.

## Future Improvements

- Real-time audio streaming between ElevenLabs and the avatar.  
- Integration with live call APIs (e.g., Twilio).  
- More advanced LLM-driven conversation handling in n8n.

## Running Locally

1. Clone the repository.  
2. Set up environment variables for Airtable and ElevenLabs API keys.  
3. Start your n8n workflow (ensure the webhook is accessible).  
4. Run the local Flask app:  
   ```bash
   python app.py
   ```
5. A browser window will open showing the Beyond Presence avatar.  
   The avatar will speak using the ElevenLabs voice output generated from the n8n workflow.
